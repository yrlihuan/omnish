# config/daemon.toml
# Daemon configuration â€” copy to ~/.omnish/daemon.toml

# Listen address:
#   Unix socket:  listen_addr = "~/.omnish/omnish.sock"   (default)
#   TCP:          listen_addr = "tcp://0.0.0.0:9500"
# sessions_dir = "~/.omnish/sessions"     # default

[llm]
default = "claude"

[llm.backends.claude]
backend_type = "anthropic"
model = "claude-sonnet-4-5-20250929"
api_key_cmd = "pass show anthropic/api-key"

# [llm.backends.openai]
# backend_type = "openai_compat"
# model = "gpt-4o"
# api_key_cmd = "pass show openai/api-key"
# base_url = "https://api.openai.com/v1"

[llm.auto_trigger]
on_nonzero_exit = true
on_stderr_patterns = ["error", "panic", "traceback", "fatal"]
cooldown_seconds = 5

[context]
# max_commands = 10       # number of recent commands included in LLM context
# head_lines = 10         # output lines kept from start of each command
# tail_lines = 10         # output lines kept from end of each command
